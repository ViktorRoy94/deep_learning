# Лабораторная работа №1

Выполнил:
 - Рой Виктор
 - ННГУ, ф-т ИТММ, каф. МО ЭВМ, группа 381603м4

## Задание
 - Изучить метод обратного распространения ошибки;
 - Вывести математические формулы для вычисления градиентов функции ошибки по параметрам
нейронной сети и формул коррекции весов;
 - Спроектировать и разработать программную реализацию;
 - Подготовить отчет по проделанной работе. 
 
## Запуск решения
 - Установить python3 c библиотекой Numpy;
 - Запустить файл main.py с аргументами 
 	- '-h' помощь 
 	- '-n' количество тренировочных изображений
 	- '-t' количество тестовых изображений
 	- '-s' количество скрытых слоев
 	- '-l' скорость обучения

Пример запуска: python main.py -n 10000 -t 1000 -s 200 -l 0.005

## Метод обратноого распространения ошибки
Функция ошибки кросс-энтропия:
$$E=-\sum_{j=1}^{N_o}t_jlog(y_j) = -\sum_{j=1}^{N_o}t_jlog(f(\sum_{s=1}^{N_s}w_s_jf(\sum_{i=1}^{N_i}w_i_sx_i)))$$

Функция активации softmax:
$$f(y_j)={{e^{y_j}}\over\sum_{j=1}^{n}e^{y_j}}$$

### Алгоритм
1. Инициализируем веса $$\inlinew_i_s$$ и $$\inlinew_s_j$$ значениями из [0,0.5]
2. Пока количество проходов < max_epoch делаем:

	Для всех картинок от 1 до number_train_images
	1. Подаем на вход $$\inlinex_i$$ и суммируем cигналы на скрытом слое $$\inlinez_s=w_0_s+\sum_{i}^{N_i}{w_i_s}x_i$$ и применяем функцию активации $$\inlinev_s=f(z_s)$$
    2. Для каждого выходного нейрона суммируем взвешенные входящие сигналы  $$\inliney_j=w_0_j+\sum_{s}^{N_s}{w_s_j}f({z_s})$$ и применяем функцию активации $$\inlineu_j=f(y_j)$$ 
	3. Считаем градиенты функции ошибки:
        
